{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install comet_ml\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import os\n",
    "import comet_ml\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/home/magali/ct_classifier/ct_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m You are trying to log string value as a metric. This is not recommended.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/magalifr/general/01a73747d1de4a3092ae734e91e64ce2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from train import load_model\n",
    "from train import create_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new model\n",
      "<class 'model.CustomResNet18'>\n",
      "torch.Size([128, 3, 224, 224])\n",
      "cuda:0\n",
      "cuda\n",
      "tensor([[ 2.3738e-01,  1.1028e+00],\n",
      "        [ 1.1589e-01,  8.9288e-01],\n",
      "        [-1.8149e-02,  1.1249e+00],\n",
      "        [-9.6606e-02,  1.3026e+00],\n",
      "        [ 4.3385e-01,  1.1026e+00],\n",
      "        [ 4.4992e-01,  1.0546e+00],\n",
      "        [-1.5733e-01,  1.2409e+00],\n",
      "        [ 1.6889e-01,  9.3068e-01],\n",
      "        [-2.3294e-02,  2.1426e+00],\n",
      "        [ 1.2406e-02,  1.7280e+00],\n",
      "        [-5.8350e-02,  1.2225e+00],\n",
      "        [-1.7825e-01,  6.4167e-01],\n",
      "        [ 2.1372e-01,  6.4688e-01],\n",
      "        [-7.5306e-01,  8.2677e-01],\n",
      "        [ 2.5958e-01,  9.2058e-01],\n",
      "        [ 6.6588e-02,  1.1084e+00],\n",
      "        [ 2.6626e-01,  2.2921e+00],\n",
      "        [-1.3852e-01,  1.0309e+00],\n",
      "        [-2.2118e-01,  8.3493e-01],\n",
      "        [ 3.6115e-02,  8.0123e-01],\n",
      "        [-3.7478e-01,  1.6744e+00],\n",
      "        [-3.1273e-01,  1.9291e+00],\n",
      "        [ 2.4650e-01,  1.2302e+00],\n",
      "        [-2.2962e-01,  1.1315e+00],\n",
      "        [-4.7882e-01,  1.3218e+00],\n",
      "        [-3.3372e-03,  8.4819e-01],\n",
      "        [-1.7108e-01,  1.6194e+00],\n",
      "        [ 7.9356e-02,  6.5881e-01],\n",
      "        [ 2.1392e-01,  5.7675e-01],\n",
      "        [ 4.2683e-02,  9.4364e-01],\n",
      "        [-6.2682e-02,  1.0146e+00],\n",
      "        [ 3.1231e-01,  1.6391e+00],\n",
      "        [ 4.3814e-02,  9.5121e-01],\n",
      "        [ 1.8801e-01,  1.0119e+00],\n",
      "        [ 1.7005e-01,  1.8214e+00],\n",
      "        [-1.9501e-01,  1.0442e+00],\n",
      "        [ 1.9101e-01,  9.3502e-01],\n",
      "        [ 3.0955e-01,  1.4632e+00],\n",
      "        [ 2.5723e-02,  1.4276e+00],\n",
      "        [ 1.4338e-01,  6.5732e-01],\n",
      "        [ 3.5482e-01,  1.3358e+00],\n",
      "        [-1.4890e-01,  1.2133e+00],\n",
      "        [-2.3570e-01,  1.1329e+00],\n",
      "        [-1.9968e-02,  9.3082e-01],\n",
      "        [ 3.3205e-01,  2.3324e+00],\n",
      "        [-2.1305e-01,  1.1095e+00],\n",
      "        [ 4.3052e-01,  1.7883e+00],\n",
      "        [ 1.4468e-01,  8.9630e-01],\n",
      "        [-2.0003e-01,  1.3932e+00],\n",
      "        [ 1.1149e-01,  7.6113e-01],\n",
      "        [-9.6025e-02,  7.9916e-01],\n",
      "        [ 5.6834e-01,  9.6202e-01],\n",
      "        [ 8.7992e-02,  8.8505e-01],\n",
      "        [ 1.7256e-01,  1.9076e+00],\n",
      "        [-5.8991e-02,  1.2957e+00],\n",
      "        [-3.2516e-01,  1.3949e+00],\n",
      "        [ 4.6221e-01,  1.1599e+00],\n",
      "        [-1.0842e-01,  1.4111e+00],\n",
      "        [-5.9628e-01,  8.9658e-01],\n",
      "        [-3.3704e-01,  1.8645e+00],\n",
      "        [-3.4242e-02,  8.7734e-01],\n",
      "        [ 2.8448e-01,  9.6132e-01],\n",
      "        [-5.5822e-02,  1.1430e+00],\n",
      "        [-5.8606e-01,  1.4549e+00],\n",
      "        [-2.6859e-03,  1.2597e+00],\n",
      "        [-3.2561e-03,  1.0519e+00],\n",
      "        [ 2.7628e-01,  9.8946e-01],\n",
      "        [ 4.0152e-01,  1.8255e+00],\n",
      "        [-4.8874e-01,  2.0094e+00],\n",
      "        [-1.6049e-01,  8.8719e-01],\n",
      "        [-1.2447e-01,  4.5449e-01],\n",
      "        [-3.2761e-01,  1.3847e+00],\n",
      "        [ 2.7965e-01,  9.8359e-01],\n",
      "        [ 1.3859e-02,  1.2931e+00],\n",
      "        [-2.8741e-02,  1.2027e+00],\n",
      "        [-1.1906e-01,  2.5038e+00],\n",
      "        [ 1.0223e-01,  9.3883e-01],\n",
      "        [ 2.2224e-02,  8.7622e-01],\n",
      "        [ 5.5229e-01,  1.2145e+00],\n",
      "        [-1.8128e-01,  1.0742e+00],\n",
      "        [ 2.3141e-01,  9.6281e-01],\n",
      "        [-5.6566e-02,  1.6470e+00],\n",
      "        [ 8.7032e-02,  4.4286e-01],\n",
      "        [-1.0721e-01,  1.3251e+00],\n",
      "        [-8.3291e-01,  1.6027e+00],\n",
      "        [-1.2538e-01,  9.8537e-01],\n",
      "        [ 2.4133e-01,  1.6051e+00],\n",
      "        [-4.3290e-01,  8.1461e-01],\n",
      "        [ 1.2061e-01,  7.2556e-01],\n",
      "        [ 2.3473e-01,  6.7309e-01],\n",
      "        [-7.8776e-03,  1.1415e+00],\n",
      "        [-9.9559e-02,  9.7204e-01],\n",
      "        [ 2.7191e-01,  1.2306e+00],\n",
      "        [-1.2227e-01,  1.8675e+00],\n",
      "        [-6.2452e-01,  1.0668e+00],\n",
      "        [ 4.2002e-02,  9.9780e-01],\n",
      "        [ 8.7288e-02,  8.7721e-01],\n",
      "        [ 8.6438e-02,  7.0735e-01],\n",
      "        [-5.2944e-01,  1.7819e+00],\n",
      "        [-3.7203e-02,  5.7613e-01],\n",
      "        [ 1.3910e-01,  1.0369e+00],\n",
      "        [-4.0600e-01,  9.6302e-01],\n",
      "        [ 1.4525e-01,  9.0338e-01],\n",
      "        [ 3.6470e-01,  2.7931e+00],\n",
      "        [ 1.8499e-01,  1.7242e+00],\n",
      "        [ 1.1686e-01,  1.3245e+00],\n",
      "        [ 7.5645e-02,  1.2559e+00],\n",
      "        [-2.5058e-01,  1.3552e+00],\n",
      "        [ 3.4931e-01,  1.1746e+00],\n",
      "        [-9.6014e-02,  2.2738e+00],\n",
      "        [-2.8211e-01,  8.8316e-01],\n",
      "        [-5.1166e-02,  1.2478e+00],\n",
      "        [-1.6795e-01,  7.4474e-01],\n",
      "        [ 1.0202e-02,  7.8687e-01],\n",
      "        [-2.8895e-01,  1.2079e+00],\n",
      "        [ 6.9000e-02,  1.4776e+00],\n",
      "        [ 4.1756e-02,  1.3422e+00],\n",
      "        [ 6.9981e-02,  7.2771e-01],\n",
      "        [ 1.3960e-01,  1.5421e+00],\n",
      "        [-4.2106e-01,  6.6854e-01],\n",
      "        [ 1.0687e-01,  6.8269e-01],\n",
      "        [-5.5001e-01,  8.8849e-01],\n",
      "        [-2.2565e-01,  1.0213e+00],\n",
      "        [ 1.4685e-01,  1.6350e+00],\n",
      "        [ 1.6754e-01,  1.6733e+00],\n",
      "        [ 2.8768e-01,  1.9571e+00],\n",
      "        [ 5.0031e-02,  6.5510e-01],\n",
      "        [ 2.4077e-01,  7.5300e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Load model and data and make predictions\n",
    "cfg = yaml.safe_load(open('../configs/exp_resnet18.yaml', 'r'))\n",
    "model, current_epoch = load_model(cfg)\n",
    "#model = torch.load('/home/magali/ct_classifier/model_states/48.pt')['model']\n",
    "print(type(model))\n",
    "\n",
    "dl_val = create_dataloader(cfg, split='val')\n",
    "\n",
    "device = cfg['device']\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():               # don't calculate intermediate gradient steps: we don't need them, so this saves memory and is faster\n",
    "        for idx, (data, labels) in enumerate(dl_val):\n",
    "\n",
    "            # put data and labels on device\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            print(data.shape)\n",
    "            #print(model.classifier.device)\n",
    "            print(data.device)\n",
    "            print(device)\n",
    "            # forward pass\n",
    "            prediction = model(data)\n",
    "            print(prediction)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2374, 1.1028], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(data[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(labels, preds)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(recall, precision, marker='.', label='Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape, type(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Cell 2: Load Model and Data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# Load model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[39m# Load CIFAR-10 test dataset\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m     11\u001b[0m     transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m     12\u001b[0m     transforms\u001b[39m.\u001b[39mNormalize((\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m), (\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m))\n\u001b[1;32m     13\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Model and Data\n",
    "\n",
    "# Load model\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = torch.load(\"model.pth\")\n",
    "#model.eval()\n",
    "#model.to(device)\n",
    "\n",
    "# Load CIFAR-10 test dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = dl_val\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Predictions\n",
    "#dataiter = iter(test_loader)\n",
    "#images, labels = dataiter.next()\n",
    "# Make predictions\n",
    "#outputs = model(images.to(device))\n",
    "#_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Function to unnormalize and display an image\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Plot images, true labels, and predicted labels\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m imshow(torchvision\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mmake_grid(images))\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrue labels: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m%5s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m classes[labels[j]] \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m16\u001b[39m)))\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPredicted labels: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m%5s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m classes[predicted[j]] \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m16\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot images, true labels, and predicted labels\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('True labels: ', ' '.join('%5s' % classes[labels[j]] for j in range(16)))\n",
    "print('Predicted labels: ', ' '.join('%5s' % classes[predicted[j]] for j in range(16)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4e_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
