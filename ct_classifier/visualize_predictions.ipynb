{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magali/miniconda3/envs/cv4e_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m You are trying to log string value as a metric. This is not recommended.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/magalifr/general/d028e61a028e4dd2ad7dee3b673a9808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "#from ct_classifier/ct_classifier.train import create_dataloader, load_model       # NOTE: since we're using these functions across files, it could make sense to put them in e.g. a \"util.py\" script.\n",
    "from train import load_model\n",
    "from train import create_dataloader\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import softmax as softmax\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = '/home/magali/ct_classifier/configs/exp_resnet18_sex.yaml'\n",
    "split = 'val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config \"/home/magali/ct_classifier/configs/exp_resnet18_sex.yaml\"\n",
      "val number of images 1540 labels 1540 images covered 1540\n",
      "Resuming from epoch 2\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "print(f'Using config \"{config}\"')\n",
    "cfg = yaml.safe_load(open(config, 'r'))\n",
    "\n",
    "\n",
    "# setup entities\n",
    "dl_val = create_dataloader(cfg, split='val')\n",
    "\n",
    "# load model\n",
    "model = load_model(cfg)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "\n",
    "This is up to you to figure out now. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'model.CustomResNet18'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "#print(model)\n",
    "#print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomResNet18(\n",
       "  (feature_extractor): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = cfg['device']\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_labels = []\n",
    "all_labels = []\n",
    "all_img_path = []\n",
    "\n",
    "def tuple_to_list(obj):\n",
    "    if isinstance(obj, tuple):\n",
    "        return [tuple_to_list(item) for item in obj]\n",
    "    return obj\n",
    "\n",
    "with torch.no_grad():               # don't calculate intermediate gradient steps: we don't need them, so this saves memory and is faster\n",
    "        for idx, (data, labels, img_path) in enumerate(dl_val):\n",
    "\n",
    "            # put data and labels on device\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            print(data.shape)\n",
    "            #print(model.classifier.device)\n",
    "            print(data.device)\n",
    "            print(device)\n",
    "            # forward pass\n",
    "            prediction = model(data)\n",
    "            #print(prediction[0])\n",
    "            #print(img_path[0])\n",
    "\n",
    "            # If you want to track labels and paths as well, you can continue to do that\n",
    "            pred_label = prediction\n",
    "            all_pred_labels = all_pred_labels + pred_label.cpu().tolist()\n",
    "            print(all_pred_labels)\n",
    "            all_labels = all_labels + labels.tolist()\n",
    "            print(all_labels)\n",
    "\n",
    "            # Convert tuple to numpy array\n",
    "            #img_path_arr = np.array(img_path)\n",
    "            #img_path_lst = tuple_to_list(img_path)\n",
    "\n",
    "            #all_img_path = all_img_path + img_path_arr.tolist()\n",
    "\n",
    "            # Flatten the img_path tuple\n",
    "            img_path_lst = tuple_to_list(img_path)\n",
    "            all_img_path.extend(img_path_lst)\n",
    "\n",
    "            # Print sizes for debugging\n",
    "            print(f\"Iteration {idx}: all_pred_labels size: {len(all_pred_labels)}, all_labels size: {len(all_labels)}, all_img_path size: {len(all_img_path)}\")\n",
    "\n",
    "            \n",
    "        # After the loop, print or return the summed predictions\n",
    "        print(all_pred_labels, all_labels, all_img_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframes with predictions, labels and image id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df= pd.DataFrame(all_labels, columns=['Labels'])\n",
    "pred_df = pd.DataFrame(all_pred_labels, columns=['pred_female', 'pred_male'])\n",
    "img_id_df = pd.DataFrame(all_img_path, columns=['Image path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pred_female  pred_male\n",
      "0        0.591234   0.531620\n",
      "1        0.759668   0.061531\n",
      "2        0.006739   0.024211\n",
      "3        0.544882  -0.155374\n",
      "4        0.141859  -0.267443\n",
      "...           ...        ...\n",
      "1535     1.099417   0.596322\n",
      "1536    -0.228931  -0.030944\n",
      "1537     0.450738  -0.177004\n",
      "1538    -0.006079   0.319362\n",
      "1539     0.523580  -0.242675\n",
      "\n",
      "[1540 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Image path\n",
      "0     /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "1     /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "2     /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "3     /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "4     /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "...                                                 ...\n",
      "1535  /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "1536  /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "1537  /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "1538  /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "1539  /home/magali/CV4Ecology-summer-school/Prototyp...\n",
      "\n",
      "[1540 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(img_id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Labels  pred_female  pred_male  \\\n",
      "0          0     0.591234   0.531620   \n",
      "1          0     0.759668   0.061531   \n",
      "2          0     0.006739   0.024211   \n",
      "3          1     0.544882  -0.155374   \n",
      "4          0     0.141859  -0.267443   \n",
      "...      ...          ...        ...   \n",
      "1535       0     1.099417   0.596322   \n",
      "1536       1    -0.228931  -0.030944   \n",
      "1537       0     0.450738  -0.177004   \n",
      "1538       1    -0.006079   0.319362   \n",
      "1539       1     0.523580  -0.242675   \n",
      "\n",
      "                                             Image path  \n",
      "0     /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "1     /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "2     /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "3     /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "4     /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "...                                                 ...  \n",
      "1535  /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "1536  /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "1537  /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "1538  /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "1539  /home/magali/CV4Ecology-summer-school/Prototyp...  \n",
      "\n",
      "[1540 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "result = pd.concat([label_df, pred_df, img_id_df], axis=1, ignore_index=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert predictions to with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Labels  pred_female  pred_male  \\\n",
      "0          0     0.591234   0.531620   \n",
      "1          0     0.759668   0.061531   \n",
      "2          0     0.006739   0.024211   \n",
      "3          1     0.544882  -0.155374   \n",
      "4          0     0.141859  -0.267443   \n",
      "...      ...          ...        ...   \n",
      "1535       0     1.099417   0.596322   \n",
      "1536       1    -0.228931  -0.030944   \n",
      "1537       0     0.450738  -0.177004   \n",
      "1538       1    -0.006079   0.319362   \n",
      "1539       1     0.523580  -0.242675   \n",
      "\n",
      "                                             Image path  pred_female_softmax  \\\n",
      "0     /home/magali/CV4Ecology-summer-school/Prototyp...             0.514899   \n",
      "1     /home/magali/CV4Ecology-summer-school/Prototyp...             0.667775   \n",
      "2     /home/magali/CV4Ecology-summer-school/Prototyp...             0.495632   \n",
      "3     /home/magali/CV4Ecology-summer-school/Prototyp...             0.668244   \n",
      "4     /home/magali/CV4Ecology-summer-school/Prototyp...             0.600921   \n",
      "...                                                 ...                  ...   \n",
      "1535  /home/magali/CV4Ecology-summer-school/Prototyp...             0.623187   \n",
      "1536  /home/magali/CV4Ecology-summer-school/Prototyp...             0.450664   \n",
      "1537  /home/magali/CV4Ecology-summer-school/Prototyp...             0.651977   \n",
      "1538  /home/magali/CV4Ecology-summer-school/Prototyp...             0.419350   \n",
      "1539  /home/magali/CV4Ecology-summer-school/Prototyp...             0.682710   \n",
      "\n",
      "      pred_male_softmax  \n",
      "0              0.485101  \n",
      "1              0.332225  \n",
      "2              0.504368  \n",
      "3              0.331756  \n",
      "4              0.399079  \n",
      "...                 ...  \n",
      "1535           0.376813  \n",
      "1536           0.549336  \n",
      "1537           0.348023  \n",
      "1538           0.580650  \n",
      "1539           0.317290  \n",
      "\n",
      "[1540 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define a function to apply torch.softmax to a list of scores\n",
    "#def apply_softmax(scores):\n",
    "#    tensor_scores = torch.tensor(scores)\n",
    "#    softmax_scores = torch.softmax(tensor_scores, dim=0).tolist()  # Using dim=0 for 1D tensor\n",
    "#    return softmax_scores\n",
    "\n",
    "# Apply the function to the 'prediction' column\n",
    "#result['pred_female_softmax'] = result['pred_female'].apply(torch.softmax)\n",
    "#result['pred_male_softmax'] = result['pred_male'].apply(apply_softmax)\n",
    "\n",
    "# Convert DataFrame columns to a tensor\n",
    "tensor_predictions = torch.tensor(result[['pred_female', 'pred_male']].values)\n",
    "\n",
    "# Compute softmax along the last dimension (across columns for each row)\n",
    "softmax_tensor = torch.softmax(tensor_predictions, dim=1)\n",
    "\n",
    "# Convert the tensor back to a DataFrame\n",
    "df_softmax = pd.DataFrame(softmax_tensor.numpy(), columns=['pred_female_softmax', 'pred_male_softmax'])\n",
    "\n",
    "# Concatenate the two DataFrames along axis=1\n",
    "result = pd.concat([result, df_softmax], axis=1)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Labels  pred_female  pred_male  \\\n",
      "0          0     0.591234   0.531620   \n",
      "1          0     0.759668   0.061531   \n",
      "2          0     0.006739   0.024211   \n",
      "3          1     0.544882  -0.155374   \n",
      "4          0     0.141859  -0.267443   \n",
      "...      ...          ...        ...   \n",
      "1535       0     1.099417   0.596322   \n",
      "1536       1    -0.228931  -0.030944   \n",
      "1537       0     0.450738  -0.177004   \n",
      "1538       1    -0.006079   0.319362   \n",
      "1539       1     0.523580  -0.242675   \n",
      "\n",
      "                                             Image path  pred_female_softmax  \\\n",
      "0     /home/magali/CV4Ecology-summer-school/Prototyp...             0.514899   \n",
      "1     /home/magali/CV4Ecology-summer-school/Prototyp...             0.667775   \n",
      "2     /home/magali/CV4Ecology-summer-school/Prototyp...             0.495632   \n",
      "3     /home/magali/CV4Ecology-summer-school/Prototyp...             0.668244   \n",
      "4     /home/magali/CV4Ecology-summer-school/Prototyp...             0.600921   \n",
      "...                                                 ...                  ...   \n",
      "1535  /home/magali/CV4Ecology-summer-school/Prototyp...             0.623187   \n",
      "1536  /home/magali/CV4Ecology-summer-school/Prototyp...             0.450664   \n",
      "1537  /home/magali/CV4Ecology-summer-school/Prototyp...             0.651977   \n",
      "1538  /home/magali/CV4Ecology-summer-school/Prototyp...             0.419350   \n",
      "1539  /home/magali/CV4Ecology-summer-school/Prototyp...             0.682710   \n",
      "\n",
      "      pred_male_softmax  \n",
      "0              0.485101  \n",
      "1              0.332225  \n",
      "2              0.504368  \n",
      "3              0.331756  \n",
      "4              0.399079  \n",
      "...                 ...  \n",
      "1535           0.376813  \n",
      "1536           0.549336  \n",
      "1537           0.348023  \n",
      "1538           0.580650  \n",
      "1539           0.317290  \n",
      "\n",
      "[1540 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../predictions/predictions_sex_basic.csv', index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cv4ecology')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b27dacca5370489415b54faaef213ba5af0308969d5b20dbb1ea9eafcbd86bc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
